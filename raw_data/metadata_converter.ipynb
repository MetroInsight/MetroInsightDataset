{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:rdflib:RDFLib Version: 4.2.1\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import rdflib\n",
    "from uuid import uuid4 as uuid\n",
    "import json\n",
    "import pandas as pd\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from rdflib import Namespace, Literal, URIRef, BNode\n",
    "from rdflib import RDF, RDFS, OWL, XSD\n",
    "\n",
    "WS = Namespace(\"http://metroinsight.io/schema/workspace#\")\n",
    "CORE = Namespace(\"http://metroinsight.io/schema/core#\")\n",
    "BRICK = Namespace(\"http://buildsys.org/ontologies/Brick#\")\n",
    "BF = Namespace(\"http://buildsys.org/ontologies/BrickFrame#\")\n",
    "GEO = Namespace(\"http://www.w3.org/2003/01/geo/wgs84_pos#\")\n",
    "SSN = Namespace(\"http://www.w3.org/ns/ssn/\")\n",
    "UNIT = Namespace(\"http://qudt.org/vocab/unit/\")\n",
    "QUDT = Namespace(\"http://qudt.org/schema/qudt/\")\n",
    "SCHEMAORG = Namespace(\"https://schema.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_default_graph():\n",
    "    unitSet = set()\n",
    "    g = rdflib.Graph()\n",
    "    g.bind('ws', WS)\n",
    "    g.bind('core', CORE)\n",
    "    g.bind('brick', BRICK)\n",
    "    g.bind('bf', BF)\n",
    "    g.bind('geo', GEO)\n",
    "    g.bind('ssn', SSN)\n",
    "    g.bind('unit', UNIT)\n",
    "    g.bind('qudt', QUDT)\n",
    "    g.bind('schema', SCHEMAORG)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_sensor(g, data_ref, sensor_type_str, sensor_label_str='', unit_str=None, latitude=None, longitude=None, altitude=None):\n",
    "    #Init sensor\n",
    "    sensor = WS[urllib.quote(str(uuid()), safe='')]\n",
    "    g.add((sensor, RDF.type, SSN.Sensor))\n",
    "    sensor_label = Literal(urllib.quote(sensor_label_str, safe=''), datatype=XSD.string)\n",
    "    g.add((sensor, RDFS.label, sensor_label))\n",
    "    \n",
    "    # Property (SSN Style)\n",
    "    prop = WS[urllib.quote(sensor_type_str, safe='')] # TODO: <- This needs to be standardized.\n",
    "    g.add((prop, RDF.type, SSN.Property))\n",
    "    g.add((sensor, SSN.observes, prop))\n",
    "    \n",
    "    # Point location\n",
    "    if latitude and longitude:\n",
    "        loc = BNode()\n",
    "        g.add((loc, RDF.type, GEO.Point))\n",
    "        g.add((loc, GEO.long,  Literal(float(longitude), datatype=XSD.float)))\n",
    "        g.add((loc, GEO.lat,  Literal(float(latitude), datatype=XSD.float)))\n",
    "        if altitude:\n",
    "            g.add((loc, GEO.alt,  Literal(float(altitude), datatype=XSD.float)))\n",
    "        g.add((sensor, SCHEMAORG.location, loc))\n",
    "    \n",
    "    # Data Stream\n",
    "    #sensor_data = WS[urllib.quote(str(uuid()), safe='')]\n",
    "    sensor_data = BNode()\n",
    "    g.add((sensor_data, RDF.type, CORE.DataStream))\n",
    "    g.add((sensor, SSN.hasOutput, sensor_data))\n",
    "    \n",
    "    # Data Reference\n",
    "    g.add((sensor_data, CORE.hasDataReference, Literal(str(data_ref), datatype=XSD.string)))\n",
    "    \n",
    "    # Data Unit\n",
    "    if unit_str:\n",
    "        g.add((sensor_data, QUDT.unit, UNIT[unit_str]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BD mapping\n",
    "\n",
    "with open(\"buildingdepot/config/bd3config.json\", \"r\") as fp:\n",
    "    configs = json.load(fp)\n",
    "    valid_naes = configs['valid_naes']\n",
    "with open(\"buildingdepot/config/bd2_1config.json\", \"r\") as fp:\n",
    "    configs = json.load(fp)\n",
    "    valid_naes += configs['valid_naes']\n",
    "with open(\"buildingdepot/metadata/bacnet_devices.json\", \"r\") as fp:\n",
    "    bacnet_devices = json.load(fp)\n",
    "with open(\"buildingdepot/metadata/building_info.json\", \"r\") as fp:\n",
    "    building_info_dict = json.load(fp)\n",
    "with open(\"buildingdepot/metadata/bacnetunit_to_qudt_unit.json\", \"r\") as fp:\n",
    "    bacnet_unit_map = json.load(fp)\n",
    "\n",
    "for nae_num in valid_naes:\n",
    "    g = get_default_graph()\n",
    "    objs = bacnet_devices[nae_num]['objs']\n",
    "    location = None\n",
    "    for building_name, building in building_info_dict.items():\n",
    "        if int(nae_num) in building['naes']:\n",
    "            location = building['location']\n",
    "            latitude = location['latitude']\n",
    "            longitude = location['longitude']\n",
    "            break\n",
    "    if location==None:\n",
    "        print str(nae_num)\n",
    "        print \"nae is not found in building_info_dict\" \n",
    "    for obj in objs:\n",
    "        if obj['data_type'] not in [0,1,2,3,4,5,13,14,19]:\n",
    "            continue \n",
    "        srcid = str(nae_num) + \"_\" + str(obj['data_type']) + \"_\" + str(obj['props']['instance'])\n",
    "        bacnet_unit = str(obj['unit'])\n",
    "        qudt_unit = bacnet_unit_map.get(bacnet_unit)\n",
    "        data_ref = 'raw_data/buildingdepot/data/%s.csv'%srcid\n",
    "        sensor_type_str = obj['jci_name']\n",
    "        make_sensor(g, data_ref, sensor_type_str, unit_str=qudt_unit, latitude=latitude, longitude=longitude, altitude=None)\n",
    "    g.serialize('buildingdepot/normalized_metadata/bd_%s_metro.ttl'%(nae_num), format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Google traffic mapping\n",
    "\n",
    "with open('google_traffic/config/google_traffic_config.json', 'r') as fp:\n",
    "    configs = json.load(fp)\n",
    "    base_url = configs['db_url']\n",
    "with open('google_traffic/metadata/google_traffic_metadata.json', 'r') as fp:\n",
    "    route_dict = json.load(fp)\n",
    "    \n",
    "g = get_default_graph()\n",
    "\n",
    "for route_name, route in route_dict.items():\n",
    "    latitude = route['location']['latitude']\n",
    "    longitude = route['location']['longitude']\n",
    "    qudt_unit = UNIT.SEC\n",
    "    data_ref = 'raw_data/google_traffiic/data/%s.csv'%route_name\n",
    "    sensor_type_str = \"Travel Time\"\n",
    "    make_sensor(g, data_ref, sensor_type_str, unit_str=qudt_unit, latitude=latitude, longitude=longitude, altitude=None)\n",
    "g.serialize('google_traffic_metro.ttl', format='turtle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
